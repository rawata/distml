{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.tree.RandomForest\n",
    "import org.apache.spark.mllib.tree.model.RandomForestModel\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "\n",
    "//Data is in libsvm format: sparse data\n",
    "val data = MLUtils.loadLibSVMFile(sc, \"./data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val (trainingData, testData) = (splits(0), splits(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Train a RandomForest model.\n",
    "// Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "val numClasses = 2\n",
    "val categoricalFeaturesInfo = Map[Int, Int]()\n",
    "val numTrees = 3 // Use more in practice.\n",
    "val featureSubsetStrategy = \"auto\" // Let the algorithm choose.\n",
    "val impurity = \"gini\"\n",
    "val maxDepth = 4\n",
    "val maxBins = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val model = RandomForest.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n",
    "  numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val labelAndPredicts = testData.map{ point => \n",
    "    val prediction = model.predict(point.features)\n",
    "    (point.label, prediction)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//build the metrics for model evaluation\n",
    "val metrics = new BinaryClassificationMetrics(labelAndPredicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification error = 0.02564102564102564\n",
      "Test areaUnderPR = 0.9943019943019943.\n",
      "Test areaUnderROC = 0.9814814814814814.\n"
     ]
    }
   ],
   "source": [
    "val testErr = labelAndPredicts.filter(x => x._1 != x._2).count.toDouble/labelAndPredicts.count \n",
    "println(s\"Test Classification error = $testErr\")\n",
    "println(s\"Test areaUnderPR = ${metrics.areaUnderPR()}.\")\n",
    "println(s\"Test areaUnderROC = ${metrics.areaUnderROC()}.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
